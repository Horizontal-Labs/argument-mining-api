{
  "best_global_step": 6548,
  "best_metric": 0.9608277082443237,
  "best_model_checkpoint": "./argument-mining-modernbert-adu_classification\\checkpoint-6548",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 6548,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006108735491753207,
      "grad_norm": 4.84755277633667,
      "learning_rate": 3.865717192268566e-07,
      "loss": 0.8406,
      "step": 20
    },
    {
      "epoch": 0.012217470983506415,
      "grad_norm": 8.085053443908691,
      "learning_rate": 7.934893184130214e-07,
      "loss": 0.8475,
      "step": 40
    },
    {
      "epoch": 0.01832620647525962,
      "grad_norm": 4.96268892288208,
      "learning_rate": 1.2004069175991862e-06,
      "loss": 0.8291,
      "step": 60
    },
    {
      "epoch": 0.02443494196701283,
      "grad_norm": 7.072898864746094,
      "learning_rate": 1.607324516785351e-06,
      "loss": 0.7655,
      "step": 80
    },
    {
      "epoch": 0.030543677458766034,
      "grad_norm": 5.0886335372924805,
      "learning_rate": 2.014242115971516e-06,
      "loss": 0.8045,
      "step": 100
    },
    {
      "epoch": 0.03665241295051924,
      "grad_norm": 4.988218307495117,
      "learning_rate": 2.4211597151576806e-06,
      "loss": 0.7407,
      "step": 120
    },
    {
      "epoch": 0.04276114844227245,
      "grad_norm": 6.804940223693848,
      "learning_rate": 2.8280773143438456e-06,
      "loss": 0.7204,
      "step": 140
    },
    {
      "epoch": 0.04886988393402566,
      "grad_norm": 4.140203952789307,
      "learning_rate": 3.23499491353001e-06,
      "loss": 0.7069,
      "step": 160
    },
    {
      "epoch": 0.05497861942577886,
      "grad_norm": 4.176047325134277,
      "learning_rate": 3.641912512716175e-06,
      "loss": 0.6657,
      "step": 180
    },
    {
      "epoch": 0.06108735491753207,
      "grad_norm": 5.1423749923706055,
      "learning_rate": 4.04883011190234e-06,
      "loss": 0.6207,
      "step": 200
    },
    {
      "epoch": 0.06719609040928527,
      "grad_norm": 3.246673345565796,
      "learning_rate": 4.455747711088505e-06,
      "loss": 0.5468,
      "step": 220
    },
    {
      "epoch": 0.07330482590103848,
      "grad_norm": 9.102899551391602,
      "learning_rate": 4.86266531027467e-06,
      "loss": 0.5403,
      "step": 240
    },
    {
      "epoch": 0.0794135613927917,
      "grad_norm": 3.726734161376953,
      "learning_rate": 5.269582909460834e-06,
      "loss": 0.4681,
      "step": 260
    },
    {
      "epoch": 0.0855222968845449,
      "grad_norm": 3.704228162765503,
      "learning_rate": 5.676500508647e-06,
      "loss": 0.4311,
      "step": 280
    },
    {
      "epoch": 0.0916310323762981,
      "grad_norm": 2.5144598484039307,
      "learning_rate": 6.083418107833164e-06,
      "loss": 0.3489,
      "step": 300
    },
    {
      "epoch": 0.09773976786805132,
      "grad_norm": 2.4490292072296143,
      "learning_rate": 6.49033570701933e-06,
      "loss": 0.3496,
      "step": 320
    },
    {
      "epoch": 0.10384850335980451,
      "grad_norm": 13.158052444458008,
      "learning_rate": 6.897253306205493e-06,
      "loss": 0.3248,
      "step": 340
    },
    {
      "epoch": 0.10995723885155773,
      "grad_norm": 2.766216516494751,
      "learning_rate": 7.304170905391659e-06,
      "loss": 0.3109,
      "step": 360
    },
    {
      "epoch": 0.11606597434331094,
      "grad_norm": 3.1678714752197266,
      "learning_rate": 7.711088504577823e-06,
      "loss": 0.2759,
      "step": 380
    },
    {
      "epoch": 0.12217470983506414,
      "grad_norm": 1.827346682548523,
      "learning_rate": 8.11800610376399e-06,
      "loss": 0.273,
      "step": 400
    },
    {
      "epoch": 0.12828344532681735,
      "grad_norm": 1.4046846628189087,
      "learning_rate": 8.524923702950153e-06,
      "loss": 0.2181,
      "step": 420
    },
    {
      "epoch": 0.13439218081857054,
      "grad_norm": 2.603008985519409,
      "learning_rate": 8.931841302136319e-06,
      "loss": 0.2475,
      "step": 440
    },
    {
      "epoch": 0.14050091631032377,
      "grad_norm": 3.920405387878418,
      "learning_rate": 9.338758901322483e-06,
      "loss": 0.2653,
      "step": 460
    },
    {
      "epoch": 0.14660965180207697,
      "grad_norm": 3.141352891921997,
      "learning_rate": 9.745676500508648e-06,
      "loss": 0.2015,
      "step": 480
    },
    {
      "epoch": 0.15271838729383017,
      "grad_norm": 8.074406623840332,
      "learning_rate": 1.0152594099694813e-05,
      "loss": 0.2104,
      "step": 500
    },
    {
      "epoch": 0.1588271227855834,
      "grad_norm": 3.3027052879333496,
      "learning_rate": 1.0559511698880977e-05,
      "loss": 0.2233,
      "step": 520
    },
    {
      "epoch": 0.1649358582773366,
      "grad_norm": 0.799342691898346,
      "learning_rate": 1.0966429298067143e-05,
      "loss": 0.1831,
      "step": 540
    },
    {
      "epoch": 0.1710445937690898,
      "grad_norm": 1.1289169788360596,
      "learning_rate": 1.1373346897253308e-05,
      "loss": 0.1882,
      "step": 560
    },
    {
      "epoch": 0.177153329260843,
      "grad_norm": 1.2099162340164185,
      "learning_rate": 1.1780264496439473e-05,
      "loss": 0.19,
      "step": 580
    },
    {
      "epoch": 0.1832620647525962,
      "grad_norm": 2.129564046859741,
      "learning_rate": 1.2187182095625635e-05,
      "loss": 0.174,
      "step": 600
    },
    {
      "epoch": 0.1893708002443494,
      "grad_norm": 13.081446647644043,
      "learning_rate": 1.2594099694811802e-05,
      "loss": 0.1726,
      "step": 620
    },
    {
      "epoch": 0.19547953573610263,
      "grad_norm": 2.7475674152374268,
      "learning_rate": 1.3001017293997966e-05,
      "loss": 0.2118,
      "step": 640
    },
    {
      "epoch": 0.20158827122785583,
      "grad_norm": 1.2972378730773926,
      "learning_rate": 1.340793489318413e-05,
      "loss": 0.1241,
      "step": 660
    },
    {
      "epoch": 0.20769700671960903,
      "grad_norm": 3.239638566970825,
      "learning_rate": 1.3814852492370297e-05,
      "loss": 0.1479,
      "step": 680
    },
    {
      "epoch": 0.21380574221136225,
      "grad_norm": 1.6336036920547485,
      "learning_rate": 1.4221770091556462e-05,
      "loss": 0.1839,
      "step": 700
    },
    {
      "epoch": 0.21991447770311545,
      "grad_norm": 2.2876272201538086,
      "learning_rate": 1.4628687690742626e-05,
      "loss": 0.1926,
      "step": 720
    },
    {
      "epoch": 0.22602321319486865,
      "grad_norm": 3.2616212368011475,
      "learning_rate": 1.5035605289928789e-05,
      "loss": 0.1616,
      "step": 740
    },
    {
      "epoch": 0.23213194868662188,
      "grad_norm": 4.45165491104126,
      "learning_rate": 1.5442522889114954e-05,
      "loss": 0.2082,
      "step": 760
    },
    {
      "epoch": 0.23824068417837507,
      "grad_norm": 5.44346809387207,
      "learning_rate": 1.5849440488301118e-05,
      "loss": 0.118,
      "step": 780
    },
    {
      "epoch": 0.24434941967012827,
      "grad_norm": 3.1534624099731445,
      "learning_rate": 1.6256358087487286e-05,
      "loss": 0.137,
      "step": 800
    },
    {
      "epoch": 0.25045815516188147,
      "grad_norm": 0.21836644411087036,
      "learning_rate": 1.666327568667345e-05,
      "loss": 0.1075,
      "step": 820
    },
    {
      "epoch": 0.2565668906536347,
      "grad_norm": 4.322232723236084,
      "learning_rate": 1.7070193285859615e-05,
      "loss": 0.142,
      "step": 840
    },
    {
      "epoch": 0.2626756261453879,
      "grad_norm": 2.5319106578826904,
      "learning_rate": 1.747711088504578e-05,
      "loss": 0.2014,
      "step": 860
    },
    {
      "epoch": 0.2687843616371411,
      "grad_norm": 3.5019166469573975,
      "learning_rate": 1.7884028484231945e-05,
      "loss": 0.1377,
      "step": 880
    },
    {
      "epoch": 0.2748930971288943,
      "grad_norm": 5.365482330322266,
      "learning_rate": 1.829094608341811e-05,
      "loss": 0.1469,
      "step": 900
    },
    {
      "epoch": 0.28100183262064754,
      "grad_norm": 3.294059991836548,
      "learning_rate": 1.8697863682604274e-05,
      "loss": 0.097,
      "step": 920
    },
    {
      "epoch": 0.2871105681124007,
      "grad_norm": 1.019840955734253,
      "learning_rate": 1.9104781281790438e-05,
      "loss": 0.1434,
      "step": 940
    },
    {
      "epoch": 0.29321930360415394,
      "grad_norm": 2.6898210048675537,
      "learning_rate": 1.9511698880976603e-05,
      "loss": 0.1766,
      "step": 960
    },
    {
      "epoch": 0.29932803909590716,
      "grad_norm": 6.713951110839844,
      "learning_rate": 1.9918616480162767e-05,
      "loss": 0.1872,
      "step": 980
    },
    {
      "epoch": 0.30543677458766033,
      "grad_norm": 5.797602653503418,
      "learning_rate": 1.9963796809593846e-05,
      "loss": 0.216,
      "step": 1000
    },
    {
      "epoch": 0.31154551007941356,
      "grad_norm": 6.445205211639404,
      "learning_rate": 1.9918542821586154e-05,
      "loss": 0.1964,
      "step": 1020
    },
    {
      "epoch": 0.3176542455711668,
      "grad_norm": 3.207613229751587,
      "learning_rate": 1.987328883357846e-05,
      "loss": 0.085,
      "step": 1040
    },
    {
      "epoch": 0.32376298106291995,
      "grad_norm": 3.8043344020843506,
      "learning_rate": 1.982803484557077e-05,
      "loss": 0.1926,
      "step": 1060
    },
    {
      "epoch": 0.3298717165546732,
      "grad_norm": 9.091595649719238,
      "learning_rate": 1.9782780857563076e-05,
      "loss": 0.161,
      "step": 1080
    },
    {
      "epoch": 0.3359804520464264,
      "grad_norm": 0.6946340799331665,
      "learning_rate": 1.973752686955538e-05,
      "loss": 0.1302,
      "step": 1100
    },
    {
      "epoch": 0.3420891875381796,
      "grad_norm": 0.92485511302948,
      "learning_rate": 1.9692272881547688e-05,
      "loss": 0.152,
      "step": 1120
    },
    {
      "epoch": 0.3481979230299328,
      "grad_norm": 0.8918634057044983,
      "learning_rate": 1.9647018893539995e-05,
      "loss": 0.1148,
      "step": 1140
    },
    {
      "epoch": 0.354306658521686,
      "grad_norm": 4.188294410705566,
      "learning_rate": 1.9601764905532303e-05,
      "loss": 0.2034,
      "step": 1160
    },
    {
      "epoch": 0.3604153940134392,
      "grad_norm": 1.944873571395874,
      "learning_rate": 1.955651091752461e-05,
      "loss": 0.1606,
      "step": 1180
    },
    {
      "epoch": 0.3665241295051924,
      "grad_norm": 1.5810190439224243,
      "learning_rate": 1.9511256929516914e-05,
      "loss": 0.2045,
      "step": 1200
    },
    {
      "epoch": 0.37263286499694565,
      "grad_norm": 3.7719531059265137,
      "learning_rate": 1.9466002941509222e-05,
      "loss": 0.1368,
      "step": 1220
    },
    {
      "epoch": 0.3787416004886988,
      "grad_norm": 1.643711805343628,
      "learning_rate": 1.942074895350153e-05,
      "loss": 0.1199,
      "step": 1240
    },
    {
      "epoch": 0.38485033598045204,
      "grad_norm": 9.826862335205078,
      "learning_rate": 1.9375494965493837e-05,
      "loss": 0.1369,
      "step": 1260
    },
    {
      "epoch": 0.39095907147220527,
      "grad_norm": 9.852204322814941,
      "learning_rate": 1.9330240977486144e-05,
      "loss": 0.1121,
      "step": 1280
    },
    {
      "epoch": 0.39706780696395844,
      "grad_norm": 3.896327257156372,
      "learning_rate": 1.928498698947845e-05,
      "loss": 0.1848,
      "step": 1300
    },
    {
      "epoch": 0.40317654245571166,
      "grad_norm": 6.281339645385742,
      "learning_rate": 1.9239733001470756e-05,
      "loss": 0.143,
      "step": 1320
    },
    {
      "epoch": 0.4092852779474649,
      "grad_norm": 4.739316940307617,
      "learning_rate": 1.9194479013463063e-05,
      "loss": 0.0848,
      "step": 1340
    },
    {
      "epoch": 0.41539401343921806,
      "grad_norm": 0.38492003083229065,
      "learning_rate": 1.9149225025455367e-05,
      "loss": 0.1932,
      "step": 1360
    },
    {
      "epoch": 0.4215027489309713,
      "grad_norm": 0.2256789356470108,
      "learning_rate": 1.910397103744768e-05,
      "loss": 0.1224,
      "step": 1380
    },
    {
      "epoch": 0.4276114844227245,
      "grad_norm": 2.392400026321411,
      "learning_rate": 1.9058717049439982e-05,
      "loss": 0.1627,
      "step": 1400
    },
    {
      "epoch": 0.4337202199144777,
      "grad_norm": 0.9764625430107117,
      "learning_rate": 1.901346306143229e-05,
      "loss": 0.117,
      "step": 1420
    },
    {
      "epoch": 0.4398289554062309,
      "grad_norm": 2.5111234188079834,
      "learning_rate": 1.8968209073424597e-05,
      "loss": 0.1518,
      "step": 1440
    },
    {
      "epoch": 0.44593769089798413,
      "grad_norm": 1.0329725742340088,
      "learning_rate": 1.89229550854169e-05,
      "loss": 0.1875,
      "step": 1460
    },
    {
      "epoch": 0.4520464263897373,
      "grad_norm": 1.7688498497009277,
      "learning_rate": 1.8877701097409212e-05,
      "loss": 0.1362,
      "step": 1480
    },
    {
      "epoch": 0.4581551618814905,
      "grad_norm": 1.1058635711669922,
      "learning_rate": 1.8832447109401516e-05,
      "loss": 0.1326,
      "step": 1500
    },
    {
      "epoch": 0.46426389737324375,
      "grad_norm": 2.3104076385498047,
      "learning_rate": 1.8787193121393824e-05,
      "loss": 0.1762,
      "step": 1520
    },
    {
      "epoch": 0.4703726328649969,
      "grad_norm": 2.270155191421509,
      "learning_rate": 1.874193913338613e-05,
      "loss": 0.1835,
      "step": 1540
    },
    {
      "epoch": 0.47648136835675015,
      "grad_norm": 0.24157586693763733,
      "learning_rate": 1.8696685145378436e-05,
      "loss": 0.1272,
      "step": 1560
    },
    {
      "epoch": 0.48259010384850337,
      "grad_norm": 0.3384955823421478,
      "learning_rate": 1.8651431157370746e-05,
      "loss": 0.1265,
      "step": 1580
    },
    {
      "epoch": 0.48869883934025654,
      "grad_norm": 0.2084207534790039,
      "learning_rate": 1.860617716936305e-05,
      "loss": 0.1586,
      "step": 1600
    },
    {
      "epoch": 0.49480757483200977,
      "grad_norm": 4.2139458656311035,
      "learning_rate": 1.8560923181355358e-05,
      "loss": 0.1656,
      "step": 1620
    },
    {
      "epoch": 0.5009163103237629,
      "grad_norm": 4.588108062744141,
      "learning_rate": 1.8515669193347665e-05,
      "loss": 0.1457,
      "step": 1640
    },
    {
      "epoch": 0.5070250458155162,
      "grad_norm": 0.7413572072982788,
      "learning_rate": 1.847041520533997e-05,
      "loss": 0.1502,
      "step": 1660
    },
    {
      "epoch": 0.5131337813072694,
      "grad_norm": 3.0585687160491943,
      "learning_rate": 1.842516121733228e-05,
      "loss": 0.19,
      "step": 1680
    },
    {
      "epoch": 0.5192425167990226,
      "grad_norm": 5.251201152801514,
      "learning_rate": 1.8379907229324585e-05,
      "loss": 0.1397,
      "step": 1700
    },
    {
      "epoch": 0.5253512522907758,
      "grad_norm": 4.049193382263184,
      "learning_rate": 1.8334653241316892e-05,
      "loss": 0.1103,
      "step": 1720
    },
    {
      "epoch": 0.531459987782529,
      "grad_norm": 2.368298053741455,
      "learning_rate": 1.82893992533092e-05,
      "loss": 0.1875,
      "step": 1740
    },
    {
      "epoch": 0.5375687232742822,
      "grad_norm": 6.897918701171875,
      "learning_rate": 1.8244145265301507e-05,
      "loss": 0.0918,
      "step": 1760
    },
    {
      "epoch": 0.5436774587660355,
      "grad_norm": 8.061460494995117,
      "learning_rate": 1.8198891277293815e-05,
      "loss": 0.1305,
      "step": 1780
    },
    {
      "epoch": 0.5497861942577886,
      "grad_norm": 2.7086217403411865,
      "learning_rate": 1.815363728928612e-05,
      "loss": 0.1504,
      "step": 1800
    },
    {
      "epoch": 0.5558949297495418,
      "grad_norm": 1.2446708679199219,
      "learning_rate": 1.8108383301278426e-05,
      "loss": 0.1525,
      "step": 1820
    },
    {
      "epoch": 0.5620036652412951,
      "grad_norm": 0.5576440691947937,
      "learning_rate": 1.8063129313270734e-05,
      "loss": 0.134,
      "step": 1840
    },
    {
      "epoch": 0.5681124007330483,
      "grad_norm": 5.0918450355529785,
      "learning_rate": 1.801787532526304e-05,
      "loss": 0.1534,
      "step": 1860
    },
    {
      "epoch": 0.5742211362248014,
      "grad_norm": 3.6443254947662354,
      "learning_rate": 1.797262133725535e-05,
      "loss": 0.1604,
      "step": 1880
    },
    {
      "epoch": 0.5803298717165547,
      "grad_norm": 5.529804229736328,
      "learning_rate": 1.7927367349247653e-05,
      "loss": 0.1405,
      "step": 1900
    },
    {
      "epoch": 0.5864386072083079,
      "grad_norm": 3.578212261199951,
      "learning_rate": 1.788211336123996e-05,
      "loss": 0.1821,
      "step": 1920
    },
    {
      "epoch": 0.592547342700061,
      "grad_norm": 0.12041740119457245,
      "learning_rate": 1.7836859373232268e-05,
      "loss": 0.0784,
      "step": 1940
    },
    {
      "epoch": 0.5986560781918143,
      "grad_norm": 1.7412760257720947,
      "learning_rate": 1.7791605385224575e-05,
      "loss": 0.1241,
      "step": 1960
    },
    {
      "epoch": 0.6047648136835675,
      "grad_norm": 4.613335609436035,
      "learning_rate": 1.7746351397216883e-05,
      "loss": 0.1601,
      "step": 1980
    },
    {
      "epoch": 0.6108735491753207,
      "grad_norm": 9.545036315917969,
      "learning_rate": 1.7701097409209187e-05,
      "loss": 0.1594,
      "step": 2000
    },
    {
      "epoch": 0.6169822846670739,
      "grad_norm": 0.3108564615249634,
      "learning_rate": 1.7655843421201494e-05,
      "loss": 0.0865,
      "step": 2020
    },
    {
      "epoch": 0.6230910201588271,
      "grad_norm": 0.039654653519392014,
      "learning_rate": 1.76105894331938e-05,
      "loss": 0.1707,
      "step": 2040
    },
    {
      "epoch": 0.6291997556505803,
      "grad_norm": 6.7247185707092285,
      "learning_rate": 1.756533544518611e-05,
      "loss": 0.0841,
      "step": 2060
    },
    {
      "epoch": 0.6353084911423336,
      "grad_norm": 1.4596854448318481,
      "learning_rate": 1.7520081457178417e-05,
      "loss": 0.1406,
      "step": 2080
    },
    {
      "epoch": 0.6414172266340867,
      "grad_norm": 1.8919426202774048,
      "learning_rate": 1.7474827469170724e-05,
      "loss": 0.1861,
      "step": 2100
    },
    {
      "epoch": 0.6475259621258399,
      "grad_norm": 3.506575584411621,
      "learning_rate": 1.7429573481163028e-05,
      "loss": 0.1493,
      "step": 2120
    },
    {
      "epoch": 0.6536346976175932,
      "grad_norm": 1.0234251022338867,
      "learning_rate": 1.7384319493155336e-05,
      "loss": 0.1004,
      "step": 2140
    },
    {
      "epoch": 0.6597434331093464,
      "grad_norm": 1.544776201248169,
      "learning_rate": 1.7339065505147643e-05,
      "loss": 0.1727,
      "step": 2160
    },
    {
      "epoch": 0.6658521686010995,
      "grad_norm": 3.6840806007385254,
      "learning_rate": 1.729381151713995e-05,
      "loss": 0.1301,
      "step": 2180
    },
    {
      "epoch": 0.6719609040928528,
      "grad_norm": 1.0792285203933716,
      "learning_rate": 1.7248557529132258e-05,
      "loss": 0.1932,
      "step": 2200
    },
    {
      "epoch": 0.678069639584606,
      "grad_norm": 3.4087140560150146,
      "learning_rate": 1.7203303541124562e-05,
      "loss": 0.1353,
      "step": 2220
    },
    {
      "epoch": 0.6841783750763591,
      "grad_norm": 2.99027943611145,
      "learning_rate": 1.715804955311687e-05,
      "loss": 0.1294,
      "step": 2240
    },
    {
      "epoch": 0.6902871105681124,
      "grad_norm": 3.3693654537200928,
      "learning_rate": 1.7112795565109177e-05,
      "loss": 0.1603,
      "step": 2260
    },
    {
      "epoch": 0.6963958460598656,
      "grad_norm": 0.782044529914856,
      "learning_rate": 1.706754157710148e-05,
      "loss": 0.0789,
      "step": 2280
    },
    {
      "epoch": 0.7025045815516188,
      "grad_norm": 5.786312580108643,
      "learning_rate": 1.7022287589093792e-05,
      "loss": 0.1454,
      "step": 2300
    },
    {
      "epoch": 0.708613317043372,
      "grad_norm": 8.285324096679688,
      "learning_rate": 1.6977033601086096e-05,
      "loss": 0.0859,
      "step": 2320
    },
    {
      "epoch": 0.7147220525351252,
      "grad_norm": 0.7112727165222168,
      "learning_rate": 1.6931779613078404e-05,
      "loss": 0.1059,
      "step": 2340
    },
    {
      "epoch": 0.7208307880268784,
      "grad_norm": 5.099998474121094,
      "learning_rate": 1.688652562507071e-05,
      "loss": 0.0962,
      "step": 2360
    },
    {
      "epoch": 0.7269395235186317,
      "grad_norm": 12.628052711486816,
      "learning_rate": 1.6841271637063015e-05,
      "loss": 0.1059,
      "step": 2380
    },
    {
      "epoch": 0.7330482590103848,
      "grad_norm": 11.969450950622559,
      "learning_rate": 1.6796017649055326e-05,
      "loss": 0.1357,
      "step": 2400
    },
    {
      "epoch": 0.739156994502138,
      "grad_norm": 5.959491729736328,
      "learning_rate": 1.675076366104763e-05,
      "loss": 0.1158,
      "step": 2420
    },
    {
      "epoch": 0.7452657299938913,
      "grad_norm": 6.41493558883667,
      "learning_rate": 1.6705509673039938e-05,
      "loss": 0.1336,
      "step": 2440
    },
    {
      "epoch": 0.7513744654856445,
      "grad_norm": 2.779723882675171,
      "learning_rate": 1.6660255685032245e-05,
      "loss": 0.1653,
      "step": 2460
    },
    {
      "epoch": 0.7574832009773976,
      "grad_norm": 6.161223888397217,
      "learning_rate": 1.661500169702455e-05,
      "loss": 0.1427,
      "step": 2480
    },
    {
      "epoch": 0.7635919364691509,
      "grad_norm": 2.6244215965270996,
      "learning_rate": 1.656974770901686e-05,
      "loss": 0.1034,
      "step": 2500
    },
    {
      "epoch": 0.7697006719609041,
      "grad_norm": 7.422360897064209,
      "learning_rate": 1.6524493721009164e-05,
      "loss": 0.0669,
      "step": 2520
    },
    {
      "epoch": 0.7758094074526573,
      "grad_norm": 0.22259889543056488,
      "learning_rate": 1.6479239733001472e-05,
      "loss": 0.1322,
      "step": 2540
    },
    {
      "epoch": 0.7819181429444105,
      "grad_norm": 0.022322041913866997,
      "learning_rate": 1.643398574499378e-05,
      "loss": 0.06,
      "step": 2560
    },
    {
      "epoch": 0.7880268784361637,
      "grad_norm": 6.865041255950928,
      "learning_rate": 1.6388731756986083e-05,
      "loss": 0.1899,
      "step": 2580
    },
    {
      "epoch": 0.7941356139279169,
      "grad_norm": 9.830246925354004,
      "learning_rate": 1.6343477768978394e-05,
      "loss": 0.206,
      "step": 2600
    },
    {
      "epoch": 0.8002443494196702,
      "grad_norm": 1.1245568990707397,
      "learning_rate": 1.62982237809707e-05,
      "loss": 0.1163,
      "step": 2620
    },
    {
      "epoch": 0.8063530849114233,
      "grad_norm": 1.02939772605896,
      "learning_rate": 1.6252969792963006e-05,
      "loss": 0.1048,
      "step": 2640
    },
    {
      "epoch": 0.8124618204031765,
      "grad_norm": 3.8087451457977295,
      "learning_rate": 1.6207715804955313e-05,
      "loss": 0.0826,
      "step": 2660
    },
    {
      "epoch": 0.8185705558949298,
      "grad_norm": 0.3890552222728729,
      "learning_rate": 1.6162461816947618e-05,
      "loss": 0.1034,
      "step": 2680
    },
    {
      "epoch": 0.8246792913866829,
      "grad_norm": 1.1620038747787476,
      "learning_rate": 1.611720782893993e-05,
      "loss": 0.1238,
      "step": 2700
    },
    {
      "epoch": 0.8307880268784361,
      "grad_norm": 11.694221496582031,
      "learning_rate": 1.6071953840932232e-05,
      "loss": 0.1762,
      "step": 2720
    },
    {
      "epoch": 0.8368967623701894,
      "grad_norm": 0.21024763584136963,
      "learning_rate": 1.602669985292454e-05,
      "loss": 0.1872,
      "step": 2740
    },
    {
      "epoch": 0.8430054978619426,
      "grad_norm": 17.978885650634766,
      "learning_rate": 1.5981445864916847e-05,
      "loss": 0.1512,
      "step": 2760
    },
    {
      "epoch": 0.8491142333536957,
      "grad_norm": 0.20653481781482697,
      "learning_rate": 1.593619187690915e-05,
      "loss": 0.0541,
      "step": 2780
    },
    {
      "epoch": 0.855222968845449,
      "grad_norm": 2.617443561553955,
      "learning_rate": 1.5890937888901462e-05,
      "loss": 0.1868,
      "step": 2800
    },
    {
      "epoch": 0.8613317043372022,
      "grad_norm": 9.051200866699219,
      "learning_rate": 1.5845683900893767e-05,
      "loss": 0.1833,
      "step": 2820
    },
    {
      "epoch": 0.8674404398289554,
      "grad_norm": 0.44479045271873474,
      "learning_rate": 1.5800429912886074e-05,
      "loss": 0.1048,
      "step": 2840
    },
    {
      "epoch": 0.8735491753207086,
      "grad_norm": 4.907381534576416,
      "learning_rate": 1.575517592487838e-05,
      "loss": 0.118,
      "step": 2860
    },
    {
      "epoch": 0.8796579108124618,
      "grad_norm": 5.275325775146484,
      "learning_rate": 1.570992193687069e-05,
      "loss": 0.1725,
      "step": 2880
    },
    {
      "epoch": 0.885766646304215,
      "grad_norm": 3.3250184059143066,
      "learning_rate": 1.5664667948862996e-05,
      "loss": 0.1177,
      "step": 2900
    },
    {
      "epoch": 0.8918753817959683,
      "grad_norm": 5.795904636383057,
      "learning_rate": 1.56194139608553e-05,
      "loss": 0.0875,
      "step": 2920
    },
    {
      "epoch": 0.8979841172877214,
      "grad_norm": 4.499290466308594,
      "learning_rate": 1.5574159972847608e-05,
      "loss": 0.1564,
      "step": 2940
    },
    {
      "epoch": 0.9040928527794746,
      "grad_norm": 0.30536824464797974,
      "learning_rate": 1.5528905984839916e-05,
      "loss": 0.1439,
      "step": 2960
    },
    {
      "epoch": 0.9102015882712279,
      "grad_norm": 0.24189861118793488,
      "learning_rate": 1.5483651996832223e-05,
      "loss": 0.1738,
      "step": 2980
    },
    {
      "epoch": 0.916310323762981,
      "grad_norm": 7.325833797454834,
      "learning_rate": 1.543839800882453e-05,
      "loss": 0.1475,
      "step": 3000
    },
    {
      "epoch": 0.9224190592547342,
      "grad_norm": 0.8743510246276855,
      "learning_rate": 1.5393144020816835e-05,
      "loss": 0.1408,
      "step": 3020
    },
    {
      "epoch": 0.9285277947464875,
      "grad_norm": 6.991251468658447,
      "learning_rate": 1.5347890032809142e-05,
      "loss": 0.0653,
      "step": 3040
    },
    {
      "epoch": 0.9346365302382407,
      "grad_norm": 8.625234603881836,
      "learning_rate": 1.530263604480145e-05,
      "loss": 0.1415,
      "step": 3060
    },
    {
      "epoch": 0.9407452657299938,
      "grad_norm": 1.4765194654464722,
      "learning_rate": 1.5257382056793757e-05,
      "loss": 0.1305,
      "step": 3080
    },
    {
      "epoch": 0.9468540012217471,
      "grad_norm": 0.053986307233572006,
      "learning_rate": 1.5212128068786063e-05,
      "loss": 0.0854,
      "step": 3100
    },
    {
      "epoch": 0.9529627367135003,
      "grad_norm": 4.599025249481201,
      "learning_rate": 1.5166874080778369e-05,
      "loss": 0.1044,
      "step": 3120
    },
    {
      "epoch": 0.9590714722052535,
      "grad_norm": 0.1977684199810028,
      "learning_rate": 1.5121620092770676e-05,
      "loss": 0.0736,
      "step": 3140
    },
    {
      "epoch": 0.9651802076970067,
      "grad_norm": 9.056936264038086,
      "learning_rate": 1.5076366104762984e-05,
      "loss": 0.1383,
      "step": 3160
    },
    {
      "epoch": 0.9712889431887599,
      "grad_norm": 0.14568039774894714,
      "learning_rate": 1.5031112116755291e-05,
      "loss": 0.1481,
      "step": 3180
    },
    {
      "epoch": 0.9773976786805131,
      "grad_norm": 0.12036606669425964,
      "learning_rate": 1.4985858128747597e-05,
      "loss": 0.1353,
      "step": 3200
    },
    {
      "epoch": 0.9835064141722664,
      "grad_norm": 0.45994529128074646,
      "learning_rate": 1.4940604140739904e-05,
      "loss": 0.1052,
      "step": 3220
    },
    {
      "epoch": 0.9896151496640195,
      "grad_norm": 5.8966546058654785,
      "learning_rate": 1.489535015273221e-05,
      "loss": 0.104,
      "step": 3240
    },
    {
      "epoch": 0.9957238851557727,
      "grad_norm": 6.359655857086182,
      "learning_rate": 1.4850096164724516e-05,
      "loss": 0.13,
      "step": 3260
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9564752578735352,
      "eval_loss": 0.14691630005836487,
      "eval_runtime": 215.1565,
      "eval_samples_per_second": 60.867,
      "eval_steps_per_second": 7.608,
      "step": 3274
    },
    {
      "epoch": 1.0018326206475259,
      "grad_norm": 1.7121771574020386,
      "learning_rate": 1.4804842176716825e-05,
      "loss": 0.131,
      "step": 3280
    },
    {
      "epoch": 1.0079413561392792,
      "grad_norm": 3.8579699993133545,
      "learning_rate": 1.4759588188709131e-05,
      "loss": 0.1362,
      "step": 3300
    },
    {
      "epoch": 1.0140500916310324,
      "grad_norm": 4.7339582443237305,
      "learning_rate": 1.4714334200701438e-05,
      "loss": 0.1431,
      "step": 3320
    },
    {
      "epoch": 1.0201588271227855,
      "grad_norm": 5.626222610473633,
      "learning_rate": 1.4669080212693744e-05,
      "loss": 0.1694,
      "step": 3340
    },
    {
      "epoch": 1.0262675626145388,
      "grad_norm": 0.3288339674472809,
      "learning_rate": 1.462382622468605e-05,
      "loss": 0.1343,
      "step": 3360
    },
    {
      "epoch": 1.032376298106292,
      "grad_norm": 6.804165363311768,
      "learning_rate": 1.457857223667836e-05,
      "loss": 0.1405,
      "step": 3380
    },
    {
      "epoch": 1.0384850335980451,
      "grad_norm": 3.464179277420044,
      "learning_rate": 1.4533318248670665e-05,
      "loss": 0.0573,
      "step": 3400
    },
    {
      "epoch": 1.0445937690897984,
      "grad_norm": 0.18570823967456818,
      "learning_rate": 1.4488064260662972e-05,
      "loss": 0.1806,
      "step": 3420
    },
    {
      "epoch": 1.0507025045815517,
      "grad_norm": 0.8838643431663513,
      "learning_rate": 1.4442810272655278e-05,
      "loss": 0.0964,
      "step": 3440
    },
    {
      "epoch": 1.0568112400733047,
      "grad_norm": 0.3735726475715637,
      "learning_rate": 1.4397556284647584e-05,
      "loss": 0.1734,
      "step": 3460
    },
    {
      "epoch": 1.062919975565058,
      "grad_norm": 0.6925730109214783,
      "learning_rate": 1.4352302296639893e-05,
      "loss": 0.1447,
      "step": 3480
    },
    {
      "epoch": 1.0690287110568113,
      "grad_norm": 0.1544015109539032,
      "learning_rate": 1.4307048308632199e-05,
      "loss": 0.078,
      "step": 3500
    },
    {
      "epoch": 1.0751374465485644,
      "grad_norm": 6.147372245788574,
      "learning_rate": 1.4261794320624507e-05,
      "loss": 0.1469,
      "step": 3520
    },
    {
      "epoch": 1.0812461820403176,
      "grad_norm": 1.2339861392974854,
      "learning_rate": 1.4216540332616812e-05,
      "loss": 0.1226,
      "step": 3540
    },
    {
      "epoch": 1.087354917532071,
      "grad_norm": 0.10304847359657288,
      "learning_rate": 1.4171286344609121e-05,
      "loss": 0.0588,
      "step": 3560
    },
    {
      "epoch": 1.093463653023824,
      "grad_norm": 4.22847843170166,
      "learning_rate": 1.4126032356601427e-05,
      "loss": 0.1069,
      "step": 3580
    },
    {
      "epoch": 1.0995723885155773,
      "grad_norm": 5.888726711273193,
      "learning_rate": 1.4080778368593733e-05,
      "loss": 0.1888,
      "step": 3600
    },
    {
      "epoch": 1.1056811240073305,
      "grad_norm": 6.346417427062988,
      "learning_rate": 1.403552438058604e-05,
      "loss": 0.1232,
      "step": 3620
    },
    {
      "epoch": 1.1117898594990836,
      "grad_norm": 2.6348726749420166,
      "learning_rate": 1.3990270392578346e-05,
      "loss": 0.0959,
      "step": 3640
    },
    {
      "epoch": 1.1178985949908369,
      "grad_norm": 3.3089957237243652,
      "learning_rate": 1.3945016404570656e-05,
      "loss": 0.0721,
      "step": 3660
    },
    {
      "epoch": 1.1240073304825902,
      "grad_norm": 0.9895122051239014,
      "learning_rate": 1.3899762416562961e-05,
      "loss": 0.092,
      "step": 3680
    },
    {
      "epoch": 1.1301160659743432,
      "grad_norm": 9.348396301269531,
      "learning_rate": 1.3854508428555267e-05,
      "loss": 0.1228,
      "step": 3700
    },
    {
      "epoch": 1.1362248014660965,
      "grad_norm": 1.933752179145813,
      "learning_rate": 1.3809254440547575e-05,
      "loss": 0.1141,
      "step": 3720
    },
    {
      "epoch": 1.1423335369578498,
      "grad_norm": 0.5567929148674011,
      "learning_rate": 1.376400045253988e-05,
      "loss": 0.1316,
      "step": 3740
    },
    {
      "epoch": 1.1484422724496028,
      "grad_norm": 4.877406120300293,
      "learning_rate": 1.371874646453219e-05,
      "loss": 0.1207,
      "step": 3760
    },
    {
      "epoch": 1.1545510079413561,
      "grad_norm": 2.3434433937072754,
      "learning_rate": 1.3673492476524495e-05,
      "loss": 0.116,
      "step": 3780
    },
    {
      "epoch": 1.1606597434331094,
      "grad_norm": 2.180760145187378,
      "learning_rate": 1.3628238488516801e-05,
      "loss": 0.0982,
      "step": 3800
    },
    {
      "epoch": 1.1667684789248625,
      "grad_norm": 7.245707988739014,
      "learning_rate": 1.3582984500509109e-05,
      "loss": 0.0786,
      "step": 3820
    },
    {
      "epoch": 1.1728772144166157,
      "grad_norm": 0.23020972311496735,
      "learning_rate": 1.3537730512501414e-05,
      "loss": 0.0895,
      "step": 3840
    },
    {
      "epoch": 1.178985949908369,
      "grad_norm": 3.7639946937561035,
      "learning_rate": 1.3492476524493724e-05,
      "loss": 0.0843,
      "step": 3860
    },
    {
      "epoch": 1.185094685400122,
      "grad_norm": 10.785368919372559,
      "learning_rate": 1.344722253648603e-05,
      "loss": 0.1004,
      "step": 3880
    },
    {
      "epoch": 1.1912034208918754,
      "grad_norm": 0.4963742792606354,
      "learning_rate": 1.3401968548478337e-05,
      "loss": 0.1471,
      "step": 3900
    },
    {
      "epoch": 1.1973121563836286,
      "grad_norm": 1.20449960231781,
      "learning_rate": 1.3356714560470643e-05,
      "loss": 0.1538,
      "step": 3920
    },
    {
      "epoch": 1.2034208918753817,
      "grad_norm": 7.279855251312256,
      "learning_rate": 1.3311460572462948e-05,
      "loss": 0.1099,
      "step": 3940
    },
    {
      "epoch": 1.209529627367135,
      "grad_norm": 8.84109878540039,
      "learning_rate": 1.3266206584455256e-05,
      "loss": 0.1213,
      "step": 3960
    },
    {
      "epoch": 1.2156383628588883,
      "grad_norm": 12.752795219421387,
      "learning_rate": 1.3220952596447563e-05,
      "loss": 0.1274,
      "step": 3980
    },
    {
      "epoch": 1.2217470983506413,
      "grad_norm": 4.577392101287842,
      "learning_rate": 1.3175698608439871e-05,
      "loss": 0.1367,
      "step": 4000
    },
    {
      "epoch": 1.2278558338423946,
      "grad_norm": 0.39477935433387756,
      "learning_rate": 1.3130444620432177e-05,
      "loss": 0.0855,
      "step": 4020
    },
    {
      "epoch": 1.2339645693341479,
      "grad_norm": 0.1377960592508316,
      "learning_rate": 1.3085190632424483e-05,
      "loss": 0.0762,
      "step": 4040
    },
    {
      "epoch": 1.240073304825901,
      "grad_norm": 0.44357046484947205,
      "learning_rate": 1.303993664441679e-05,
      "loss": 0.1016,
      "step": 4060
    },
    {
      "epoch": 1.2461820403176542,
      "grad_norm": 1.2138901948928833,
      "learning_rate": 1.2994682656409097e-05,
      "loss": 0.1243,
      "step": 4080
    },
    {
      "epoch": 1.2522907758094075,
      "grad_norm": 9.326179504394531,
      "learning_rate": 1.2949428668401405e-05,
      "loss": 0.1711,
      "step": 4100
    },
    {
      "epoch": 1.2583995113011608,
      "grad_norm": 1.8596203327178955,
      "learning_rate": 1.290417468039371e-05,
      "loss": 0.0805,
      "step": 4120
    },
    {
      "epoch": 1.2645082467929138,
      "grad_norm": 8.080992698669434,
      "learning_rate": 1.2858920692386017e-05,
      "loss": 0.0993,
      "step": 4140
    },
    {
      "epoch": 1.2706169822846671,
      "grad_norm": 7.143099308013916,
      "learning_rate": 1.2813666704378324e-05,
      "loss": 0.1352,
      "step": 4160
    },
    {
      "epoch": 1.2767257177764204,
      "grad_norm": 1.6669234037399292,
      "learning_rate": 1.276841271637063e-05,
      "loss": 0.1299,
      "step": 4180
    },
    {
      "epoch": 1.2828344532681735,
      "grad_norm": 1.0006694793701172,
      "learning_rate": 1.2723158728362939e-05,
      "loss": 0.1058,
      "step": 4200
    },
    {
      "epoch": 1.2889431887599268,
      "grad_norm": 0.5698936581611633,
      "learning_rate": 1.2677904740355245e-05,
      "loss": 0.0903,
      "step": 4220
    },
    {
      "epoch": 1.29505192425168,
      "grad_norm": 4.880450248718262,
      "learning_rate": 1.263265075234755e-05,
      "loss": 0.1335,
      "step": 4240
    },
    {
      "epoch": 1.301160659743433,
      "grad_norm": 4.223921298980713,
      "learning_rate": 1.2587396764339858e-05,
      "loss": 0.0672,
      "step": 4260
    },
    {
      "epoch": 1.3072693952351864,
      "grad_norm": 4.276134014129639,
      "learning_rate": 1.2542142776332164e-05,
      "loss": 0.094,
      "step": 4280
    },
    {
      "epoch": 1.3133781307269397,
      "grad_norm": 0.40833038091659546,
      "learning_rate": 1.2496888788324473e-05,
      "loss": 0.0898,
      "step": 4300
    },
    {
      "epoch": 1.3194868662186927,
      "grad_norm": 23.602508544921875,
      "learning_rate": 1.2451634800316779e-05,
      "loss": 0.1309,
      "step": 4320
    },
    {
      "epoch": 1.325595601710446,
      "grad_norm": 0.2113284468650818,
      "learning_rate": 1.2406380812309086e-05,
      "loss": 0.1283,
      "step": 4340
    },
    {
      "epoch": 1.3317043372021993,
      "grad_norm": 5.312178611755371,
      "learning_rate": 1.2361126824301392e-05,
      "loss": 0.1,
      "step": 4360
    },
    {
      "epoch": 1.3378130726939523,
      "grad_norm": 0.3369523584842682,
      "learning_rate": 1.2315872836293698e-05,
      "loss": 0.0559,
      "step": 4380
    },
    {
      "epoch": 1.3439218081857056,
      "grad_norm": 6.139956951141357,
      "learning_rate": 1.2270618848286007e-05,
      "loss": 0.1683,
      "step": 4400
    },
    {
      "epoch": 1.350030543677459,
      "grad_norm": 0.23798781633377075,
      "learning_rate": 1.2225364860278313e-05,
      "loss": 0.0809,
      "step": 4420
    },
    {
      "epoch": 1.356139279169212,
      "grad_norm": 0.16280528903007507,
      "learning_rate": 1.218011087227062e-05,
      "loss": 0.1376,
      "step": 4440
    },
    {
      "epoch": 1.3622480146609652,
      "grad_norm": 0.14464707672595978,
      "learning_rate": 1.2134856884262926e-05,
      "loss": 0.1703,
      "step": 4460
    },
    {
      "epoch": 1.3683567501527185,
      "grad_norm": 0.7835036516189575,
      "learning_rate": 1.2089602896255232e-05,
      "loss": 0.0854,
      "step": 4480
    },
    {
      "epoch": 1.3744654856444716,
      "grad_norm": 3.376152515411377,
      "learning_rate": 1.2044348908247541e-05,
      "loss": 0.1463,
      "step": 4500
    },
    {
      "epoch": 1.3805742211362249,
      "grad_norm": 8.186379432678223,
      "learning_rate": 1.1999094920239847e-05,
      "loss": 0.0787,
      "step": 4520
    },
    {
      "epoch": 1.3866829566279781,
      "grad_norm": 5.099468231201172,
      "learning_rate": 1.1953840932232154e-05,
      "loss": 0.1003,
      "step": 4540
    },
    {
      "epoch": 1.3927916921197312,
      "grad_norm": 0.12857289612293243,
      "learning_rate": 1.190858694422446e-05,
      "loss": 0.0656,
      "step": 4560
    },
    {
      "epoch": 1.3989004276114845,
      "grad_norm": 0.2941105365753174,
      "learning_rate": 1.1863332956216766e-05,
      "loss": 0.0887,
      "step": 4580
    },
    {
      "epoch": 1.4050091631032378,
      "grad_norm": 1.016231894493103,
      "learning_rate": 1.1818078968209075e-05,
      "loss": 0.1126,
      "step": 4600
    },
    {
      "epoch": 1.4111178985949908,
      "grad_norm": 8.803234100341797,
      "learning_rate": 1.1772824980201381e-05,
      "loss": 0.0754,
      "step": 4620
    },
    {
      "epoch": 1.417226634086744,
      "grad_norm": 0.8321542143821716,
      "learning_rate": 1.1727570992193688e-05,
      "loss": 0.0596,
      "step": 4640
    },
    {
      "epoch": 1.4233353695784974,
      "grad_norm": 0.6574813723564148,
      "learning_rate": 1.1682317004185994e-05,
      "loss": 0.1047,
      "step": 4660
    },
    {
      "epoch": 1.4294441050702504,
      "grad_norm": 1.3432543277740479,
      "learning_rate": 1.1637063016178303e-05,
      "loss": 0.1538,
      "step": 4680
    },
    {
      "epoch": 1.4355528405620037,
      "grad_norm": 0.4206985533237457,
      "learning_rate": 1.159180902817061e-05,
      "loss": 0.1109,
      "step": 4700
    },
    {
      "epoch": 1.441661576053757,
      "grad_norm": 8.272550582885742,
      "learning_rate": 1.1546555040162915e-05,
      "loss": 0.1526,
      "step": 4720
    },
    {
      "epoch": 1.44777031154551,
      "grad_norm": 15.519742012023926,
      "learning_rate": 1.1501301052155222e-05,
      "loss": 0.154,
      "step": 4740
    },
    {
      "epoch": 1.4538790470372633,
      "grad_norm": 7.589095115661621,
      "learning_rate": 1.1456047064147528e-05,
      "loss": 0.1104,
      "step": 4760
    },
    {
      "epoch": 1.4599877825290166,
      "grad_norm": 3.3217861652374268,
      "learning_rate": 1.1410793076139837e-05,
      "loss": 0.1123,
      "step": 4780
    },
    {
      "epoch": 1.4660965180207697,
      "grad_norm": 0.6194307208061218,
      "learning_rate": 1.1365539088132143e-05,
      "loss": 0.1209,
      "step": 4800
    },
    {
      "epoch": 1.472205253512523,
      "grad_norm": 1.417304515838623,
      "learning_rate": 1.1320285100124449e-05,
      "loss": 0.1442,
      "step": 4820
    },
    {
      "epoch": 1.4783139890042762,
      "grad_norm": 4.222010612487793,
      "learning_rate": 1.1275031112116757e-05,
      "loss": 0.1967,
      "step": 4840
    },
    {
      "epoch": 1.4844227244960293,
      "grad_norm": 15.313615798950195,
      "learning_rate": 1.1229777124109062e-05,
      "loss": 0.1654,
      "step": 4860
    },
    {
      "epoch": 1.4905314599877826,
      "grad_norm": 5.730279922485352,
      "learning_rate": 1.118452313610137e-05,
      "loss": 0.0935,
      "step": 4880
    },
    {
      "epoch": 1.4966401954795359,
      "grad_norm": 8.148003578186035,
      "learning_rate": 1.1139269148093677e-05,
      "loss": 0.0952,
      "step": 4900
    },
    {
      "epoch": 1.502748930971289,
      "grad_norm": 9.684229850769043,
      "learning_rate": 1.1094015160085983e-05,
      "loss": 0.1099,
      "step": 4920
    },
    {
      "epoch": 1.5088576664630422,
      "grad_norm": 9.72452449798584,
      "learning_rate": 1.104876117207829e-05,
      "loss": 0.1349,
      "step": 4940
    },
    {
      "epoch": 1.5149664019547955,
      "grad_norm": 0.9661075472831726,
      "learning_rate": 1.1003507184070596e-05,
      "loss": 0.1241,
      "step": 4960
    },
    {
      "epoch": 1.5210751374465485,
      "grad_norm": 5.7872443199157715,
      "learning_rate": 1.0958253196062904e-05,
      "loss": 0.0786,
      "step": 4980
    },
    {
      "epoch": 1.5271838729383018,
      "grad_norm": 13.004175186157227,
      "learning_rate": 1.0912999208055211e-05,
      "loss": 0.0755,
      "step": 5000
    },
    {
      "epoch": 1.533292608430055,
      "grad_norm": 0.5365334153175354,
      "learning_rate": 1.0867745220047519e-05,
      "loss": 0.1128,
      "step": 5020
    },
    {
      "epoch": 1.5394013439218082,
      "grad_norm": 0.4441235065460205,
      "learning_rate": 1.0822491232039825e-05,
      "loss": 0.1178,
      "step": 5040
    },
    {
      "epoch": 1.5455100794135614,
      "grad_norm": 0.19347448647022247,
      "learning_rate": 1.077723724403213e-05,
      "loss": 0.1514,
      "step": 5060
    },
    {
      "epoch": 1.5516188149053147,
      "grad_norm": 10.885612487792969,
      "learning_rate": 1.0731983256024438e-05,
      "loss": 0.1201,
      "step": 5080
    },
    {
      "epoch": 1.5577275503970678,
      "grad_norm": 5.221607208251953,
      "learning_rate": 1.0686729268016744e-05,
      "loss": 0.0926,
      "step": 5100
    },
    {
      "epoch": 1.563836285888821,
      "grad_norm": 1.9231840372085571,
      "learning_rate": 1.0641475280009053e-05,
      "loss": 0.0817,
      "step": 5120
    },
    {
      "epoch": 1.5699450213805743,
      "grad_norm": 2.0677168369293213,
      "learning_rate": 1.0596221292001359e-05,
      "loss": 0.0795,
      "step": 5140
    },
    {
      "epoch": 1.5760537568723274,
      "grad_norm": 12.487995147705078,
      "learning_rate": 1.0550967303993664e-05,
      "loss": 0.1588,
      "step": 5160
    },
    {
      "epoch": 1.5821624923640807,
      "grad_norm": 0.14270207285881042,
      "learning_rate": 1.0505713315985972e-05,
      "loss": 0.1563,
      "step": 5180
    },
    {
      "epoch": 1.588271227855834,
      "grad_norm": 10.08258056640625,
      "learning_rate": 1.0460459327978278e-05,
      "loss": 0.1306,
      "step": 5200
    },
    {
      "epoch": 1.594379963347587,
      "grad_norm": 0.45963525772094727,
      "learning_rate": 1.0415205339970587e-05,
      "loss": 0.1283,
      "step": 5220
    },
    {
      "epoch": 1.6004886988393403,
      "grad_norm": 0.09134945273399353,
      "learning_rate": 1.0369951351962893e-05,
      "loss": 0.0933,
      "step": 5240
    },
    {
      "epoch": 1.6065974343310936,
      "grad_norm": 0.421847403049469,
      "learning_rate": 1.0324697363955199e-05,
      "loss": 0.0807,
      "step": 5260
    },
    {
      "epoch": 1.6127061698228466,
      "grad_norm": 8.510360717773438,
      "learning_rate": 1.0279443375947506e-05,
      "loss": 0.1511,
      "step": 5280
    },
    {
      "epoch": 1.6188149053146,
      "grad_norm": 1.0525124073028564,
      "learning_rate": 1.0234189387939812e-05,
      "loss": 0.0678,
      "step": 5300
    },
    {
      "epoch": 1.6249236408063532,
      "grad_norm": 11.186824798583984,
      "learning_rate": 1.0188935399932121e-05,
      "loss": 0.0792,
      "step": 5320
    },
    {
      "epoch": 1.6310323762981063,
      "grad_norm": 3.969931125640869,
      "learning_rate": 1.0143681411924427e-05,
      "loss": 0.0902,
      "step": 5340
    },
    {
      "epoch": 1.6371411117898595,
      "grad_norm": 4.201878070831299,
      "learning_rate": 1.0098427423916734e-05,
      "loss": 0.0564,
      "step": 5360
    },
    {
      "epoch": 1.6432498472816128,
      "grad_norm": 0.9423319101333618,
      "learning_rate": 1.005317343590904e-05,
      "loss": 0.1032,
      "step": 5380
    },
    {
      "epoch": 1.6493585827733659,
      "grad_norm": 2.556018829345703,
      "learning_rate": 1.0007919447901346e-05,
      "loss": 0.2,
      "step": 5400
    },
    {
      "epoch": 1.6554673182651192,
      "grad_norm": 11.78598690032959,
      "learning_rate": 9.962665459893653e-06,
      "loss": 0.1865,
      "step": 5420
    },
    {
      "epoch": 1.6615760537568725,
      "grad_norm": 1.4769505262374878,
      "learning_rate": 9.91741147188596e-06,
      "loss": 0.0887,
      "step": 5440
    },
    {
      "epoch": 1.6676847892486255,
      "grad_norm": 0.267337441444397,
      "learning_rate": 9.872157483878268e-06,
      "loss": 0.1418,
      "step": 5460
    },
    {
      "epoch": 1.6737935247403788,
      "grad_norm": 0.2351824790239334,
      "learning_rate": 9.826903495870574e-06,
      "loss": 0.1304,
      "step": 5480
    },
    {
      "epoch": 1.679902260232132,
      "grad_norm": 14.061413764953613,
      "learning_rate": 9.781649507862882e-06,
      "loss": 0.0892,
      "step": 5500
    },
    {
      "epoch": 1.6860109957238851,
      "grad_norm": 1.517282247543335,
      "learning_rate": 9.736395519855189e-06,
      "loss": 0.1459,
      "step": 5520
    },
    {
      "epoch": 1.6921197312156384,
      "grad_norm": 0.7323618531227112,
      "learning_rate": 9.691141531847495e-06,
      "loss": 0.1036,
      "step": 5540
    },
    {
      "epoch": 1.6982284667073917,
      "grad_norm": 0.0565066784620285,
      "learning_rate": 9.6458875438398e-06,
      "loss": 0.119,
      "step": 5560
    },
    {
      "epoch": 1.7043372021991448,
      "grad_norm": 0.1281745433807373,
      "learning_rate": 9.600633555832108e-06,
      "loss": 0.1205,
      "step": 5580
    },
    {
      "epoch": 1.710445937690898,
      "grad_norm": 0.0937504693865776,
      "learning_rate": 9.555379567824416e-06,
      "loss": 0.1059,
      "step": 5600
    },
    {
      "epoch": 1.7165546731826513,
      "grad_norm": 3.016282796859741,
      "learning_rate": 9.510125579816723e-06,
      "loss": 0.1744,
      "step": 5620
    },
    {
      "epoch": 1.7226634086744044,
      "grad_norm": 0.17219789326190948,
      "learning_rate": 9.464871591809029e-06,
      "loss": 0.098,
      "step": 5640
    },
    {
      "epoch": 1.7287721441661577,
      "grad_norm": 6.068807125091553,
      "learning_rate": 9.419617603801335e-06,
      "loss": 0.0708,
      "step": 5660
    },
    {
      "epoch": 1.734880879657911,
      "grad_norm": 20.03986930847168,
      "learning_rate": 9.374363615793642e-06,
      "loss": 0.0975,
      "step": 5680
    },
    {
      "epoch": 1.740989615149664,
      "grad_norm": 13.526073455810547,
      "learning_rate": 9.32910962778595e-06,
      "loss": 0.1047,
      "step": 5700
    },
    {
      "epoch": 1.7470983506414173,
      "grad_norm": 6.311243534088135,
      "learning_rate": 9.283855639778257e-06,
      "loss": 0.1249,
      "step": 5720
    },
    {
      "epoch": 1.7532070861331706,
      "grad_norm": 2.448176860809326,
      "learning_rate": 9.238601651770563e-06,
      "loss": 0.1134,
      "step": 5740
    },
    {
      "epoch": 1.7593158216249236,
      "grad_norm": 7.8870344161987305,
      "learning_rate": 9.193347663762869e-06,
      "loss": 0.1394,
      "step": 5760
    },
    {
      "epoch": 1.765424557116677,
      "grad_norm": 7.794187068939209,
      "learning_rate": 9.148093675755176e-06,
      "loss": 0.1121,
      "step": 5780
    },
    {
      "epoch": 1.7715332926084302,
      "grad_norm": 1.274727702140808,
      "learning_rate": 9.102839687747484e-06,
      "loss": 0.1045,
      "step": 5800
    },
    {
      "epoch": 1.7776420281001832,
      "grad_norm": 5.305412769317627,
      "learning_rate": 9.057585699739791e-06,
      "loss": 0.0806,
      "step": 5820
    },
    {
      "epoch": 1.7837507635919365,
      "grad_norm": 8.557191848754883,
      "learning_rate": 9.012331711732097e-06,
      "loss": 0.152,
      "step": 5840
    },
    {
      "epoch": 1.7898594990836898,
      "grad_norm": 0.07184212654829025,
      "learning_rate": 8.967077723724404e-06,
      "loss": 0.0964,
      "step": 5860
    },
    {
      "epoch": 1.7959682345754429,
      "grad_norm": 5.177811145782471,
      "learning_rate": 8.92182373571671e-06,
      "loss": 0.1018,
      "step": 5880
    },
    {
      "epoch": 1.8020769700671961,
      "grad_norm": 12.283684730529785,
      "learning_rate": 8.876569747709018e-06,
      "loss": 0.1094,
      "step": 5900
    },
    {
      "epoch": 1.8081857055589494,
      "grad_norm": 8.00775146484375,
      "learning_rate": 8.831315759701325e-06,
      "loss": 0.181,
      "step": 5920
    },
    {
      "epoch": 1.8142944410507025,
      "grad_norm": 5.094246864318848,
      "learning_rate": 8.786061771693631e-06,
      "loss": 0.1152,
      "step": 5940
    },
    {
      "epoch": 1.8204031765424558,
      "grad_norm": 1.2382146120071411,
      "learning_rate": 8.740807783685938e-06,
      "loss": 0.1679,
      "step": 5960
    },
    {
      "epoch": 1.826511912034209,
      "grad_norm": 0.24251343309879303,
      "learning_rate": 8.695553795678244e-06,
      "loss": 0.1413,
      "step": 5980
    },
    {
      "epoch": 1.832620647525962,
      "grad_norm": 8.936968803405762,
      "learning_rate": 8.650299807670552e-06,
      "loss": 0.1172,
      "step": 6000
    },
    {
      "epoch": 1.8387293830177154,
      "grad_norm": 0.14342959225177765,
      "learning_rate": 8.605045819662858e-06,
      "loss": 0.0971,
      "step": 6020
    },
    {
      "epoch": 1.8448381185094687,
      "grad_norm": 3.5796360969543457,
      "learning_rate": 8.559791831655165e-06,
      "loss": 0.0831,
      "step": 6040
    },
    {
      "epoch": 1.8509468540012217,
      "grad_norm": 9.044720649719238,
      "learning_rate": 8.514537843647473e-06,
      "loss": 0.1032,
      "step": 6060
    },
    {
      "epoch": 1.857055589492975,
      "grad_norm": 0.27953484654426575,
      "learning_rate": 8.46928385563978e-06,
      "loss": 0.124,
      "step": 6080
    },
    {
      "epoch": 1.8631643249847283,
      "grad_norm": 7.141500473022461,
      "learning_rate": 8.424029867632086e-06,
      "loss": 0.0938,
      "step": 6100
    },
    {
      "epoch": 1.8692730604764813,
      "grad_norm": 0.033185750246047974,
      "learning_rate": 8.378775879624392e-06,
      "loss": 0.1215,
      "step": 6120
    },
    {
      "epoch": 1.8753817959682346,
      "grad_norm": 0.20279964804649353,
      "learning_rate": 8.333521891616699e-06,
      "loss": 0.0722,
      "step": 6140
    },
    {
      "epoch": 1.881490531459988,
      "grad_norm": 3.6252458095550537,
      "learning_rate": 8.288267903609007e-06,
      "loss": 0.1624,
      "step": 6160
    },
    {
      "epoch": 1.887599266951741,
      "grad_norm": 1.831276297569275,
      "learning_rate": 8.243013915601314e-06,
      "loss": 0.1332,
      "step": 6180
    },
    {
      "epoch": 1.8937080024434942,
      "grad_norm": 1.9310051202774048,
      "learning_rate": 8.19775992759362e-06,
      "loss": 0.1491,
      "step": 6200
    },
    {
      "epoch": 1.8998167379352475,
      "grad_norm": 0.44558829069137573,
      "learning_rate": 8.152505939585926e-06,
      "loss": 0.0762,
      "step": 6220
    },
    {
      "epoch": 1.9059254734270006,
      "grad_norm": 5.446928977966309,
      "learning_rate": 8.107251951578233e-06,
      "loss": 0.0991,
      "step": 6240
    },
    {
      "epoch": 1.9120342089187539,
      "grad_norm": 5.760131359100342,
      "learning_rate": 8.06199796357054e-06,
      "loss": 0.1065,
      "step": 6260
    },
    {
      "epoch": 1.9181429444105071,
      "grad_norm": 2.720651149749756,
      "learning_rate": 8.016743975562848e-06,
      "loss": 0.137,
      "step": 6280
    },
    {
      "epoch": 1.9242516799022602,
      "grad_norm": 0.49964451789855957,
      "learning_rate": 7.971489987555154e-06,
      "loss": 0.1306,
      "step": 6300
    },
    {
      "epoch": 1.9303604153940135,
      "grad_norm": 5.265644550323486,
      "learning_rate": 7.92623599954746e-06,
      "loss": 0.1574,
      "step": 6320
    },
    {
      "epoch": 1.9364691508857668,
      "grad_norm": 0.24912650883197784,
      "learning_rate": 7.880982011539767e-06,
      "loss": 0.1242,
      "step": 6340
    },
    {
      "epoch": 1.9425778863775198,
      "grad_norm": 3.0611908435821533,
      "learning_rate": 7.835728023532075e-06,
      "loss": 0.1227,
      "step": 6360
    },
    {
      "epoch": 1.948686621869273,
      "grad_norm": 2.126849889755249,
      "learning_rate": 7.790474035524382e-06,
      "loss": 0.0915,
      "step": 6380
    },
    {
      "epoch": 1.9547953573610264,
      "grad_norm": 4.042389869689941,
      "learning_rate": 7.745220047516688e-06,
      "loss": 0.1311,
      "step": 6400
    },
    {
      "epoch": 1.9609040928527794,
      "grad_norm": 0.6473343372344971,
      "learning_rate": 7.699966059508995e-06,
      "loss": 0.0987,
      "step": 6420
    },
    {
      "epoch": 1.9670128283445327,
      "grad_norm": 8.78283405303955,
      "learning_rate": 7.654712071501301e-06,
      "loss": 0.1955,
      "step": 6440
    },
    {
      "epoch": 1.973121563836286,
      "grad_norm": 0.10203161090612411,
      "learning_rate": 7.609458083493608e-06,
      "loss": 0.099,
      "step": 6460
    },
    {
      "epoch": 1.979230299328039,
      "grad_norm": 0.14619489014148712,
      "learning_rate": 7.564204095485915e-06,
      "loss": 0.1182,
      "step": 6480
    },
    {
      "epoch": 1.9853390348197923,
      "grad_norm": 10.260249137878418,
      "learning_rate": 7.518950107478222e-06,
      "loss": 0.1362,
      "step": 6500
    },
    {
      "epoch": 1.9914477703115456,
      "grad_norm": 9.223945617675781,
      "learning_rate": 7.4736961194705295e-06,
      "loss": 0.1596,
      "step": 6520
    },
    {
      "epoch": 1.9975565058032987,
      "grad_norm": 0.16081388294696808,
      "learning_rate": 7.428442131462835e-06,
      "loss": 0.09,
      "step": 6540
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9608277082443237,
      "eval_loss": 0.12384402006864548,
      "eval_runtime": 215.7116,
      "eval_samples_per_second": 60.711,
      "eval_steps_per_second": 7.589,
      "step": 6548
    }
  ],
  "logging_steps": 20,
  "max_steps": 9822,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.624203857969152e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
