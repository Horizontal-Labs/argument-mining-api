{
  "best_global_step": 1637,
  "best_metric": 0.5552840828895569,
  "best_model_checkpoint": "./argument-mining-modernbert-stance_classification\\checkpoint-1637",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1637,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012217470983506415,
      "grad_norm": 2.0373775959014893,
      "learning_rate": 7.723577235772359e-07,
      "loss": 0.7287,
      "step": 20
    },
    {
      "epoch": 0.02443494196701283,
      "grad_norm": 6.21848201751709,
      "learning_rate": 1.5853658536585368e-06,
      "loss": 0.7543,
      "step": 40
    },
    {
      "epoch": 0.03665241295051924,
      "grad_norm": 1.811694622039795,
      "learning_rate": 2.3983739837398375e-06,
      "loss": 0.7143,
      "step": 60
    },
    {
      "epoch": 0.04886988393402566,
      "grad_norm": 2.6934807300567627,
      "learning_rate": 3.211382113821139e-06,
      "loss": 0.7171,
      "step": 80
    },
    {
      "epoch": 0.06108735491753207,
      "grad_norm": 2.476107358932495,
      "learning_rate": 4.024390243902439e-06,
      "loss": 0.7551,
      "step": 100
    },
    {
      "epoch": 0.07330482590103848,
      "grad_norm": 2.7702202796936035,
      "learning_rate": 4.83739837398374e-06,
      "loss": 0.7086,
      "step": 120
    },
    {
      "epoch": 0.0855222968845449,
      "grad_norm": 2.1743104457855225,
      "learning_rate": 5.650406504065041e-06,
      "loss": 0.7222,
      "step": 140
    },
    {
      "epoch": 0.09773976786805132,
      "grad_norm": 4.131826877593994,
      "learning_rate": 6.463414634146342e-06,
      "loss": 0.6897,
      "step": 160
    },
    {
      "epoch": 0.10995723885155773,
      "grad_norm": 1.7771012783050537,
      "learning_rate": 7.276422764227643e-06,
      "loss": 0.7024,
      "step": 180
    },
    {
      "epoch": 0.12217470983506414,
      "grad_norm": 1.930648684501648,
      "learning_rate": 8.089430894308944e-06,
      "loss": 0.7283,
      "step": 200
    },
    {
      "epoch": 0.13439218081857054,
      "grad_norm": 2.3677263259887695,
      "learning_rate": 8.902439024390244e-06,
      "loss": 0.7012,
      "step": 220
    },
    {
      "epoch": 0.14660965180207697,
      "grad_norm": 1.4683295488357544,
      "learning_rate": 9.715447154471546e-06,
      "loss": 0.7078,
      "step": 240
    },
    {
      "epoch": 0.1588271227855834,
      "grad_norm": 2.5203583240509033,
      "learning_rate": 1.0528455284552846e-05,
      "loss": 0.7181,
      "step": 260
    },
    {
      "epoch": 0.1710445937690898,
      "grad_norm": 2.4517641067504883,
      "learning_rate": 1.1341463414634146e-05,
      "loss": 0.7155,
      "step": 280
    },
    {
      "epoch": 0.1832620647525962,
      "grad_norm": 2.7344753742218018,
      "learning_rate": 1.2154471544715448e-05,
      "loss": 0.7079,
      "step": 300
    },
    {
      "epoch": 0.19547953573610263,
      "grad_norm": 2.1329305171966553,
      "learning_rate": 1.2967479674796748e-05,
      "loss": 0.7072,
      "step": 320
    },
    {
      "epoch": 0.20769700671960903,
      "grad_norm": 2.6435976028442383,
      "learning_rate": 1.378048780487805e-05,
      "loss": 0.6989,
      "step": 340
    },
    {
      "epoch": 0.21991447770311545,
      "grad_norm": 3.4428904056549072,
      "learning_rate": 1.459349593495935e-05,
      "loss": 0.719,
      "step": 360
    },
    {
      "epoch": 0.23213194868662188,
      "grad_norm": 3.0865113735198975,
      "learning_rate": 1.540650406504065e-05,
      "loss": 0.7078,
      "step": 380
    },
    {
      "epoch": 0.24434941967012827,
      "grad_norm": 2.5478451251983643,
      "learning_rate": 1.6219512195121953e-05,
      "loss": 0.7039,
      "step": 400
    },
    {
      "epoch": 0.2565668906536347,
      "grad_norm": 2.1825785636901855,
      "learning_rate": 1.7032520325203255e-05,
      "loss": 0.7005,
      "step": 420
    },
    {
      "epoch": 0.2687843616371411,
      "grad_norm": 3.114396333694458,
      "learning_rate": 1.7845528455284557e-05,
      "loss": 0.7111,
      "step": 440
    },
    {
      "epoch": 0.28100183262064754,
      "grad_norm": 2.344566822052002,
      "learning_rate": 1.8658536585365855e-05,
      "loss": 0.7172,
      "step": 460
    },
    {
      "epoch": 0.29321930360415394,
      "grad_norm": 4.31289529800415,
      "learning_rate": 1.9471544715447157e-05,
      "loss": 0.722,
      "step": 480
    },
    {
      "epoch": 0.30543677458766033,
      "grad_norm": 2.6467597484588623,
      "learning_rate": 1.9968318624123107e-05,
      "loss": 0.7071,
      "step": 500
    },
    {
      "epoch": 0.3176542455711668,
      "grad_norm": 4.7676005363464355,
      "learning_rate": 1.9877800407331976e-05,
      "loss": 0.6983,
      "step": 520
    },
    {
      "epoch": 0.3298717165546732,
      "grad_norm": 2.3608837127685547,
      "learning_rate": 1.9787282190540848e-05,
      "loss": 0.7094,
      "step": 540
    },
    {
      "epoch": 0.3420891875381796,
      "grad_norm": 3.9424924850463867,
      "learning_rate": 1.969676397374972e-05,
      "loss": 0.7024,
      "step": 560
    },
    {
      "epoch": 0.354306658521686,
      "grad_norm": 3.015151023864746,
      "learning_rate": 1.9606245756958588e-05,
      "loss": 0.6888,
      "step": 580
    },
    {
      "epoch": 0.3665241295051924,
      "grad_norm": 4.9558281898498535,
      "learning_rate": 1.951572754016746e-05,
      "loss": 0.6904,
      "step": 600
    },
    {
      "epoch": 0.3787416004886988,
      "grad_norm": 4.024746894836426,
      "learning_rate": 1.942520932337633e-05,
      "loss": 0.6881,
      "step": 620
    },
    {
      "epoch": 0.39095907147220527,
      "grad_norm": 2.83225679397583,
      "learning_rate": 1.93346911065852e-05,
      "loss": 0.6992,
      "step": 640
    },
    {
      "epoch": 0.40317654245571166,
      "grad_norm": 5.4416399002075195,
      "learning_rate": 1.9244172889794072e-05,
      "loss": 0.7051,
      "step": 660
    },
    {
      "epoch": 0.41539401343921806,
      "grad_norm": 1.5405933856964111,
      "learning_rate": 1.9153654673002944e-05,
      "loss": 0.7006,
      "step": 680
    },
    {
      "epoch": 0.4276114844227245,
      "grad_norm": 5.420446872711182,
      "learning_rate": 1.9063136456211816e-05,
      "loss": 0.7125,
      "step": 700
    },
    {
      "epoch": 0.4398289554062309,
      "grad_norm": 1.4525525569915771,
      "learning_rate": 1.8972618239420687e-05,
      "loss": 0.6975,
      "step": 720
    },
    {
      "epoch": 0.4520464263897373,
      "grad_norm": 4.470304012298584,
      "learning_rate": 1.8882100022629556e-05,
      "loss": 0.6888,
      "step": 740
    },
    {
      "epoch": 0.46426389737324375,
      "grad_norm": 1.5053820610046387,
      "learning_rate": 1.8791581805838424e-05,
      "loss": 0.6857,
      "step": 760
    },
    {
      "epoch": 0.47648136835675015,
      "grad_norm": 2.456831455230713,
      "learning_rate": 1.8701063589047296e-05,
      "loss": 0.6984,
      "step": 780
    },
    {
      "epoch": 0.48869883934025654,
      "grad_norm": 3.190539598464966,
      "learning_rate": 1.8610545372256168e-05,
      "loss": 0.7028,
      "step": 800
    },
    {
      "epoch": 0.5009163103237629,
      "grad_norm": 2.590606451034546,
      "learning_rate": 1.852002715546504e-05,
      "loss": 0.6894,
      "step": 820
    },
    {
      "epoch": 0.5131337813072694,
      "grad_norm": 1.786249041557312,
      "learning_rate": 1.842950893867391e-05,
      "loss": 0.6855,
      "step": 840
    },
    {
      "epoch": 0.5253512522907758,
      "grad_norm": 2.7720580101013184,
      "learning_rate": 1.833899072188278e-05,
      "loss": 0.6831,
      "step": 860
    },
    {
      "epoch": 0.5375687232742822,
      "grad_norm": 1.4907150268554688,
      "learning_rate": 1.8248472505091652e-05,
      "loss": 0.6831,
      "step": 880
    },
    {
      "epoch": 0.5497861942577886,
      "grad_norm": 3.0204944610595703,
      "learning_rate": 1.815795428830052e-05,
      "loss": 0.6918,
      "step": 900
    },
    {
      "epoch": 0.5620036652412951,
      "grad_norm": 2.7649240493774414,
      "learning_rate": 1.8067436071509392e-05,
      "loss": 0.6817,
      "step": 920
    },
    {
      "epoch": 0.5742211362248014,
      "grad_norm": 1.2296977043151855,
      "learning_rate": 1.7976917854718264e-05,
      "loss": 0.6828,
      "step": 940
    },
    {
      "epoch": 0.5864386072083079,
      "grad_norm": 2.676525592803955,
      "learning_rate": 1.7886399637927136e-05,
      "loss": 0.6937,
      "step": 960
    },
    {
      "epoch": 0.5986560781918143,
      "grad_norm": 1.9281580448150635,
      "learning_rate": 1.7795881421136004e-05,
      "loss": 0.6806,
      "step": 980
    },
    {
      "epoch": 0.6108735491753207,
      "grad_norm": 2.4988036155700684,
      "learning_rate": 1.7705363204344876e-05,
      "loss": 0.6782,
      "step": 1000
    },
    {
      "epoch": 0.6230910201588271,
      "grad_norm": 1.460666298866272,
      "learning_rate": 1.7614844987553748e-05,
      "loss": 0.7022,
      "step": 1020
    },
    {
      "epoch": 0.6353084911423336,
      "grad_norm": 3.5542030334472656,
      "learning_rate": 1.7524326770762616e-05,
      "loss": 0.7007,
      "step": 1040
    },
    {
      "epoch": 0.6475259621258399,
      "grad_norm": 3.6573739051818848,
      "learning_rate": 1.7433808553971488e-05,
      "loss": 0.7043,
      "step": 1060
    },
    {
      "epoch": 0.6597434331093464,
      "grad_norm": 2.220463514328003,
      "learning_rate": 1.734329033718036e-05,
      "loss": 0.6887,
      "step": 1080
    },
    {
      "epoch": 0.6719609040928528,
      "grad_norm": 1.5749709606170654,
      "learning_rate": 1.725277212038923e-05,
      "loss": 0.6791,
      "step": 1100
    },
    {
      "epoch": 0.6841783750763591,
      "grad_norm": 3.500483751296997,
      "learning_rate": 1.71622539035981e-05,
      "loss": 0.6797,
      "step": 1120
    },
    {
      "epoch": 0.6963958460598656,
      "grad_norm": 2.623767852783203,
      "learning_rate": 1.7071735686806972e-05,
      "loss": 0.6674,
      "step": 1140
    },
    {
      "epoch": 0.708613317043372,
      "grad_norm": 2.1475675106048584,
      "learning_rate": 1.6981217470015844e-05,
      "loss": 0.699,
      "step": 1160
    },
    {
      "epoch": 0.7208307880268784,
      "grad_norm": 1.8889023065567017,
      "learning_rate": 1.6890699253224712e-05,
      "loss": 0.6907,
      "step": 1180
    },
    {
      "epoch": 0.7330482590103848,
      "grad_norm": 5.5560688972473145,
      "learning_rate": 1.6800181036433584e-05,
      "loss": 0.6924,
      "step": 1200
    },
    {
      "epoch": 0.7452657299938913,
      "grad_norm": 2.6856112480163574,
      "learning_rate": 1.6709662819642453e-05,
      "loss": 0.6921,
      "step": 1220
    },
    {
      "epoch": 0.7574832009773976,
      "grad_norm": 1.420727014541626,
      "learning_rate": 1.6619144602851324e-05,
      "loss": 0.6954,
      "step": 1240
    },
    {
      "epoch": 0.7697006719609041,
      "grad_norm": 1.6514866352081299,
      "learning_rate": 1.6528626386060196e-05,
      "loss": 0.6861,
      "step": 1260
    },
    {
      "epoch": 0.7819181429444105,
      "grad_norm": 3.1688284873962402,
      "learning_rate": 1.6438108169269068e-05,
      "loss": 0.6911,
      "step": 1280
    },
    {
      "epoch": 0.7941356139279169,
      "grad_norm": 4.937164306640625,
      "learning_rate": 1.6347589952477937e-05,
      "loss": 0.6979,
      "step": 1300
    },
    {
      "epoch": 0.8063530849114233,
      "grad_norm": 1.644557237625122,
      "learning_rate": 1.625707173568681e-05,
      "loss": 0.6946,
      "step": 1320
    },
    {
      "epoch": 0.8185705558949298,
      "grad_norm": 3.8674111366271973,
      "learning_rate": 1.616655351889568e-05,
      "loss": 0.6786,
      "step": 1340
    },
    {
      "epoch": 0.8307880268784361,
      "grad_norm": 3.6418633460998535,
      "learning_rate": 1.607603530210455e-05,
      "loss": 0.6723,
      "step": 1360
    },
    {
      "epoch": 0.8430054978619426,
      "grad_norm": 1.6722573041915894,
      "learning_rate": 1.598551708531342e-05,
      "loss": 0.6903,
      "step": 1380
    },
    {
      "epoch": 0.855222968845449,
      "grad_norm": 3.2545723915100098,
      "learning_rate": 1.5894998868522292e-05,
      "loss": 0.6903,
      "step": 1400
    },
    {
      "epoch": 0.8674404398289554,
      "grad_norm": 3.3494324684143066,
      "learning_rate": 1.580448065173116e-05,
      "loss": 0.6895,
      "step": 1420
    },
    {
      "epoch": 0.8796579108124618,
      "grad_norm": 6.229945659637451,
      "learning_rate": 1.5713962434940033e-05,
      "loss": 0.6882,
      "step": 1440
    },
    {
      "epoch": 0.8918753817959683,
      "grad_norm": 1.1468675136566162,
      "learning_rate": 1.5623444218148904e-05,
      "loss": 0.6978,
      "step": 1460
    },
    {
      "epoch": 0.9040928527794746,
      "grad_norm": 1.7545254230499268,
      "learning_rate": 1.5532926001357776e-05,
      "loss": 0.6886,
      "step": 1480
    },
    {
      "epoch": 0.916310323762981,
      "grad_norm": 2.0930733680725098,
      "learning_rate": 1.5442407784566645e-05,
      "loss": 0.69,
      "step": 1500
    },
    {
      "epoch": 0.9285277947464875,
      "grad_norm": 3.5744125843048096,
      "learning_rate": 1.5351889567775517e-05,
      "loss": 0.6925,
      "step": 1520
    },
    {
      "epoch": 0.9407452657299938,
      "grad_norm": 1.7362152338027954,
      "learning_rate": 1.5261371350984385e-05,
      "loss": 0.6751,
      "step": 1540
    },
    {
      "epoch": 0.9529627367135003,
      "grad_norm": 2.6113972663879395,
      "learning_rate": 1.5170853134193257e-05,
      "loss": 0.6959,
      "step": 1560
    },
    {
      "epoch": 0.9651802076970067,
      "grad_norm": 2.3913097381591797,
      "learning_rate": 1.5080334917402129e-05,
      "loss": 0.6929,
      "step": 1580
    },
    {
      "epoch": 0.9773976786805131,
      "grad_norm": 1.2919442653656006,
      "learning_rate": 1.4989816700610999e-05,
      "loss": 0.6854,
      "step": 1600
    },
    {
      "epoch": 0.9896151496640195,
      "grad_norm": 5.008941173553467,
      "learning_rate": 1.489929848381987e-05,
      "loss": 0.6908,
      "step": 1620
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5552840828895569,
      "eval_loss": 0.6857232451438904,
      "eval_runtime": 111.841,
      "eval_samples_per_second": 58.547,
      "eval_steps_per_second": 7.323,
      "step": 1637
    }
  ],
  "logging_steps": 20,
  "max_steps": 4911,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9060509644922880.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
